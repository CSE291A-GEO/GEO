{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88aa26c4",
   "metadata": {},
   "source": [
    "# MACO-Style Multi-Agent Content Optimization (Paper-Aligned)\n",
    "\n",
    "This notebook implements the full pipeline, including frozen corpus, evaluator with MIS/ISR/MIV, iterative optimization loop, analyst/editor agents, and hybrid selector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517388b",
   "metadata": {},
   "source": [
    "## 0) Setup & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c09c5cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca718104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, hashlib, re, textwrap\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"      # optional\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"CSE-291-GEO\"\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"GENSEE_API_KEY\"] = os.getenv(\"GENSEE_API_KEY\")\n",
    "\n",
    "# Model choices & constants\n",
    "MODEL_EVAL     = \"gemini-2.5-flash\"\n",
    "MODEL_ANALYST  = \"gemini-2.5-flash\"\n",
    "MODEL_EDITOR   = \"gemini-2.5-flash-lite\"\n",
    "TEMPERATURE_EVAL    = 0.0\n",
    "TEMPERATURE_ANALYST = 0.6\n",
    "TEMPERATURE_EDITOR  = 0.1\n",
    "\n",
    "N_QUERIES   = 3       # 5–10, the paper uses 10\n",
    "MAX_CTX     = 3       # contexts per query, the paper uses 10\n",
    "SUCCESS_TAU = 0.75     # ISR threshold\n",
    "N_ITERS     = 1       # iterations; selector often picks ~, the paper uses 10\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# TODO: update the anchors, the paper uses [0,10]\n",
    "ANCHORS = [0.00, 0.17, 0.33, 0.50, 0.67, 0.83, 1.00]\n",
    "METRICS = [\"CP\",\"AA\",\"FA\",\"KC\",\"SC\",\"AD\"]\n",
    "\n",
    "# TODO: baseline-style labeling\n",
    "# Optional: tag detection for edits (baseline-style labeling)\n",
    "TAG_PATTERNS = [\n",
    "    (\"Statistics\",    r\"\\b\\d{1,3}(,\\d{3})*(\\.\\d+)?\\s?%|\\b(?:million|billion|thousand)\\b\"),\n",
    "    (\"More Quotes\",   r\"[\\\"“][^\\\"”]{8,}[\\\"”]\"),\n",
    "    (\"Citing Sources\",r\"\\b(?:According to|Source:|cited by|as reported by)\\b\"),\n",
    "    (\"Technical Terms\", r\"\\b(latency|throughput|gradient|API|OAuth|schema|vector|embedding|protocol|REST|GraphQL)\\b\"),\n",
    "    (\"Authoritative\", r\"\\b(must|should|undoubtedly|certainly|we recommend)\\b\"),\n",
    "    (\"Fluent\",        r\".\"),  # fallback: any edit without the above\n",
    "]\n",
    "\n",
    "# Reproducibility tweaks where applicable\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf8e9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "def log_heading(h: str):\n",
    "    \"\"\"Log a heading - both prints to console and writes to log file\"\"\"\n",
    "    if DEBUG:\n",
    "        print(\"\\n\" + \"=\"*8 + \" \" + h + \" \" + \"=\"*8)\n",
    "\n",
    "def log_json(name: str, obj):\n",
    "    \"\"\"Log JSON object - both prints to console and writes to log file\"\"\"\n",
    "    if DEBUG:\n",
    "        print(f\"\\n[{name}]\")\n",
    "        try:\n",
    "            print(json.dumps(obj, ensure_ascii=False, indent=2))\n",
    "        except Exception:\n",
    "            print(str(obj)[:2000])\n",
    "\n",
    "def log_info(message: str):\n",
    "    \"\"\"Helper function to log info messages with timestamp\"\"\"\n",
    "    timestamp = datetime.now().strftime('%H:%M:%S')\n",
    "    print(f\"[{timestamp}] {message}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f29fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MACO Pipeline Log - Started at 2025-11-15 12:13:35\n",
      "Log file: logs/2025_11_15_12_13.txt\n",
      "================================================================================\n",
      "\n",
      "[LOG] All output will be saved to: logs/2025_11_15_12_13.txt\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Query Agent: generated queries ========\n",
      "1. What is an API?\n",
      "2. What is the primary benefit for developers when using APIs?\n",
      "3. How do applications communicate with each other using an API?\n",
      "\n",
      "======== Retrieval: per-query context counts ========\n",
      "- What is an API?...  | ctx=3\n",
      "- What is the primary benefit for developers when using APIs?...  | ctx=3\n",
      "- How do applications communicate with each other using an API?...  | ctx=3\n",
      "\n",
      "======== Retrieved Contexts (Full Content) ========\n",
      "\n",
      "--- Query 1: What is an API? ---\n",
      "\n",
      "[Context 1]\n",
      "An API, which stands for Application Programming Interface, acts as a middleman that enables different software applications to communicate with each other. It provides a set of rules and tools that allow one application to request data or services from another. For instance, a weather app uses an API to retrieve the latest weather data from a server. APIs are crucial for several reasons: * **Connecting Applications:** They facilitate data and feature sharing between apps, such as integrating Go...\n",
      "\n",
      "[Context 2]\n",
      "An API, which stands for application programming interface, is a set of protocols and instructions written in programming languages like C++ or JavaScript. It defines how two software components will communicate with each other. Unlike a user interface that is visible to users, APIs operate behind the scenes to enable software components to interact and exchange information. APIs can be thought of as contracts that govern how two software systems will interact. Examples of APIs include: * **YouT...\n",
      "\n",
      "[Context 3]\n",
      "An API, or application programming interface, is a set of protocols and definitions that enable different software components or programs to communicate with each other and share data. APIs define how one application can access the data or functions offered by another software program. For instance, to display weather information on a website, developers can use an API to connect with a service that provides real-time weather reports, rather than building their own system for data collection and...\n",
      "\n",
      "--- Query 2: What is the primary benefit for developers when using APIs? ---\n",
      "\n",
      "[Context 1]\n",
      "The primary benefit for developers when using APIs is increased productivity, as they can reuse existing APIs rather than building new code from scratch each time. This also enables rapid development and deployment of small, modular applications by leveraging a vast range of already-built third-party services and data sources.\n",
      "\n",
      "[Context 2]\n",
      "The primary benefit for developers when using APIs is increased developer productivity. APIs allow developers to reuse existing code and functionality instead of recreating them, which can significantly minimize application development time from months or years to weeks.\n",
      "\n",
      "[Context 3]\n",
      "The primary benefit for developers when using APIs is the ability to leverage pre-built functionalities and services. This allows them to avoid reinventing the wheel and focus on the core aspects of their application, thereby streamlining their workflow and reducing development time and costs. APIs act as effective assistants in accelerating the development process by enabling the seamless integration of functionalities and services, allowing developers to build a solid software foundation by in...\n",
      "\n",
      "--- Query 3: How do applications communicate with each other using an API? ---\n",
      "\n",
      "[Context 1]\n",
      "APIs communicate with each other through a process of requests and responses. One API acts as a client, sending requests to another API, which acts as the server. The server API then processes these requests and sends back responses. This communication relies on standard internet protocols like HTTP and data formats such as JSON. Both APIs must agree on the structure of these requests and responses. An API, or Application Programming Interface, serves as a communication channel between different...\n",
      "\n",
      "[Context 2]\n",
      "APIs enable different software components to communicate and transfer data through a request and response cycle. An API client initiates this by sending a request to an API server. This request typically includes an endpoint (a URL for a specific resource), a method (like GET, POST, PUT, DELETE), parameters, request headers, and a request body. The API server handles authentication, validates the data, and retrieves or manipulates it. Finally, the API server sends a response back to the client, ...\n",
      "\n",
      "[Context 3]\n",
      "APIs (Application Programming Interfaces) enable different software applications to communicate with each other. They act as intermediaries, allowing developers to access specific features or data from other applications or services without needing to understand their internal workings. The process involves a series of requests and responses: 1. **Request:** One application (the client) sends a request to another application (the server) through the API. This request specifies what action the cl...\n",
      "Frozen corpus saved to: corpus_e115757a99.json with 3 queries.\n",
      "\n",
      "======== Evaluator: Query & Contexts ========\n",
      "Query: What is an API?\n",
      "\n",
      "Number of contexts: 3\n",
      "\n",
      "[Context 1]\n",
      "An API, which stands for Application Programming Interface, acts as a middleman that enables different software applications to communicate with each other. It provides a set of rules and tools that allow one application to request data or services from another. For instance, a weather app uses an API to retrieve the latest weather data from a server. APIs are crucial for several reasons: * **Connecting Applications:** They facilitate data and feature sharing between apps, such as integrating Go...\n",
      "\n",
      "[Context 2]\n",
      "An API, which stands for application programming interface, is a set of protocols and instructions written in programming languages like C++ or JavaScript. It defines how two software components will communicate with each other. Unlike a user interface that is visible to users, APIs operate behind the scenes to enable software components to interact and exchange information. APIs can be thought of as contracts that govern how two software systems will interact. Examples of APIs include: * **YouT...\n",
      "\n",
      "[Context 3]\n",
      "An API, or application programming interface, is a set of protocols and definitions that enable different software components or programs to communicate with each other and share data. APIs define how one application can access the data or functions offered by another software program. For instance, to display weather information on a website, developers can use an API to connect with a service that provides real-time weather reports, rather than building their own system for data collection and...\n",
      "\n",
      "======== Evaluator Output ========\n",
      "\n",
      "[payload]\n",
      "{\n",
      "  \"answer\": \"An API, which stands for Application Programming Interface, is defined as a set of rules and definitions that allows applications to communicate with each other. Developers utilize APIs to access data or functionality from external services without needing to understand their internal implementations [CANDIDATE_ARTICLE]. Essentially, an API acts as a middleman or a contract, providing a set of protocols and instructions that enable different software components or programs to interact and exchange information. They operate behind the scenes, allowing one application to request data or services from another. For instance, a weather app can use an API to retrieve real-time weather data from a server, or a ride-sharing application might integrate Google Maps functionality via an API. APIs are crucial for modern online experiences, facilitating data and feature sharing between applications, saving developers time by leveraging existing functionalities, and enhancing security by controlling how data is exposed between different systems.\",\n",
      "  \"scores\": {\n",
      "    \"CP\": 0.83,\n",
      "    \"AA\": 1.0,\n",
      "    \"FA\": 1.0,\n",
      "    \"KC\": 0.67,\n",
      "    \"SC\": 0.17,\n",
      "    \"AD\": 0.17\n",
      "  },\n",
      "  \"why\": {\n",
      "    \"CP\": \"The candidate article is clearly cited at the end of the sentences derived from it, making its contribution prominent.\",\n",
      "    \"AA\": \"The statements attributed to the candidate article are directly and accurately quoted from its content.\",\n",
      "    \"FA\": \"The answer faithfully represents the meaning of the candidate article without any distortion.\",\n",
      "    \"KC\": \"The candidate article covers the core definition of an API (what it stands for, what it is, and its primary function), which is a key concept for the query. However, it lacks additional key concepts such as examples, how APIs work (request-response), or their broader importance/benefits, which are provided by the contexts.\",\n",
      "    \"SC\": \"The candidate article provides a definition of an API that is very similar to definitions found in the external contexts. While its content is used, it does not contribute unique semantic meaning that couldn't be derived from the other available contexts.\",\n",
      "    \"AD\": \"The candidate article contributes two sentences to the answer, which is a small portion (approximately 25%) of the total answer content. The majority of the answer, including examples, analogies, and benefits, is derived from the external contexts. Furthermore, the core definition provided by the candidate article could have been formulated using the other contexts, reducing its overall dominance.\"\n",
      "  }\n",
      "}\n",
      "\n",
      "======== Evaluator: Query & Contexts ========\n",
      "Query: What is the primary benefit for developers when using APIs?\n",
      "\n",
      "Number of contexts: 3\n",
      "\n",
      "[Context 1]\n",
      "The primary benefit for developers when using APIs is increased productivity, as they can reuse existing APIs rather than building new code from scratch each time. This also enables rapid development and deployment of small, modular applications by leveraging a vast range of already-built third-party services and data sources.\n",
      "\n",
      "[Context 2]\n",
      "The primary benefit for developers when using APIs is increased developer productivity. APIs allow developers to reuse existing code and functionality instead of recreating them, which can significantly minimize application development time from months or years to weeks.\n",
      "\n",
      "[Context 3]\n",
      "The primary benefit for developers when using APIs is the ability to leverage pre-built functionalities and services. This allows them to avoid reinventing the wheel and focus on the core aspects of their application, thereby streamlining their workflow and reducing development time and costs. APIs act as effective assistants in accelerating the development process by enabling the seamless integration of functionalities and services, allowing developers to build a solid software foundation by in...\n",
      "\n",
      "======== Evaluator Output ========\n",
      "\n",
      "[payload]\n",
      "{\n",
      "  \"answer\": \"APIs (Application Programming Interfaces) are sets of rules and definitions that enable different applications to communicate with each other. Developers utilize APIs to access data or functionality from external services without needing to understand their internal workings.\\n\\nThe primary benefit for developers when using APIs is increased productivity, as it allows them to reuse existing code and functionalities rather than building everything from scratch. This approach streamlines workflows, significantly reduces development time and costs, and enables rapid development by leveraging a vast array of pre-built third-party services and data sources. By integrating reliable and well-tested functionalities, developers can focus on the core aspects of their applications, accelerating the overall development process.\",\n",
      "  \"scores\": {\n",
      "    \"CP\": 0.83,\n",
      "    \"AA\": 1.0,\n",
      "    \"FA\": 1.0,\n",
      "    \"KC\": 0.33,\n",
      "    \"SC\": 0.33,\n",
      "    \"AD\": 0.17\n",
      "  },\n",
      "  \"why\": {\n",
      "    \"CP\": \"The candidate article is clearly cited and attributed at the beginning of the answer for its definition of API and how developers use it.\",\n",
      "    \"AA\": \"All statements attributed to the candidate article (definition of API, how developers use it) are directly from the article.\",\n",
      "    \"FA\": \"The answer accurately reflects the meaning of the candidate article without any distortion.\",\n",
      "    \"KC\": \"The candidate article provides a definition of API and explains how developers use it, which are relevant foundational concepts. However, it does not directly address the 'primary benefit' for developers, which is the core of the query. Therefore, it covers some key concepts but misses the central one for the specific query.\",\n",
      "    \"SC\": \"The candidate article uniquely defines what an API is and how developers use it, which is not explicitly covered by the external contexts. This provides a useful foundational understanding, even though the primary benefit comes from other sources.\",\n",
      "    \"AD\": \"The candidate article contributes the initial definition of API and how developers use it. However, the majority of the answer, specifically addressing the 'primary benefit' for developers, comes from the external contexts. The article's contribution is significant for context but not for the direct answer to the query's main point.\"\n",
      "  }\n",
      "}\n",
      "\n",
      "======== Evaluator: Query & Contexts ========\n",
      "Query: How do applications communicate with each other using an API?\n",
      "\n",
      "Number of contexts: 3\n",
      "\n",
      "[Context 1]\n",
      "APIs communicate with each other through a process of requests and responses. One API acts as a client, sending requests to another API, which acts as the server. The server API then processes these requests and sends back responses. This communication relies on standard internet protocols like HTTP and data formats such as JSON. Both APIs must agree on the structure of these requests and responses. An API, or Application Programming Interface, serves as a communication channel between different...\n",
      "\n",
      "[Context 2]\n",
      "APIs enable different software components to communicate and transfer data through a request and response cycle. An API client initiates this by sending a request to an API server. This request typically includes an endpoint (a URL for a specific resource), a method (like GET, POST, PUT, DELETE), parameters, request headers, and a request body. The API server handles authentication, validates the data, and retrieves or manipulates it. Finally, the API server sends a response back to the client, ...\n",
      "\n",
      "[Context 3]\n",
      "APIs (Application Programming Interfaces) enable different software applications to communicate with each other. They act as intermediaries, allowing developers to access specific features or data from other applications or services without needing to understand their internal workings. The process involves a series of requests and responses: 1. **Request:** One application (the client) sends a request to another application (the server) through the API. This request specifies what action the cl...\n"
     ]
    }
   ],
   "source": [
    "# ===== LOGGING SETUP =====\n",
    "class TeeOutput:\n",
    "    \"\"\"Class to capture stdout/stderr and write to both console and file\"\"\"\n",
    "    def __init__(self, terminal, log_file):\n",
    "        self.terminal = terminal\n",
    "        self.log_file = log_file\n",
    "        self.file_handle = None\n",
    "        self._open_file()\n",
    "        \n",
    "    def _open_file(self):\n",
    "        \"\"\"Open file handle for writing\"\"\"\n",
    "        self.file_handle = open(self.log_file, 'w', encoding='utf-8')\n",
    "        \n",
    "    def write(self, message):\n",
    "        # Write to terminal\n",
    "        self.terminal.write(message)\n",
    "        # Write to file (only if message is not empty)\n",
    "        if message and self.file_handle:\n",
    "            self.file_handle.write(message)\n",
    "            self.file_handle.flush()\n",
    "        \n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        if self.file_handle:\n",
    "            self.file_handle.flush()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close file handle\"\"\"\n",
    "        if self.file_handle:\n",
    "            self.file_handle.close()\n",
    "            self.file_handle = None\n",
    "\n",
    "def setup_logging():\n",
    "    \"\"\"Setup logging to timestamped file. Returns log file path.\"\"\"\n",
    "    now = datetime.now()\n",
    "    # Create logs directory if it doesn't exist\n",
    "    log_dir = \"logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    # Create filename: YYYY_MM_DD_HH_MM.txt (e.g., 2025_01_15_14_30.txt)\n",
    "    log_filename = f\"{now.year:04d}_{now.month:02d}_{now.day:02d}_{now.hour:02d}_{now.minute:02d}.txt\"\n",
    "    log_path = os.path.join(log_dir, log_filename)\n",
    "    \n",
    "    # Store original stdout/stderr\n",
    "    original_stdout = sys.stdout\n",
    "    original_stderr = sys.stderr\n",
    "    \n",
    "    # Create TeeOutput instances (they will open the file)\n",
    "    tee_stdout = TeeOutput(original_stdout, log_path)\n",
    "    tee_stderr = TeeOutput(original_stderr, log_path)\n",
    "    \n",
    "    # Redirect stdout and stderr to TeeOutput\n",
    "    sys.stdout = tee_stdout\n",
    "    sys.stderr = tee_stderr\n",
    "    \n",
    "    # Write header (this will go through TeeOutput, so no duplication)\n",
    "    print('='*80)\n",
    "    print(f\"MACO Pipeline Log - Started at {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Log file: {log_path}\")\n",
    "    print('='*80 + '\\n')\n",
    "    \n",
    "    return log_path\n",
    "\n",
    "# Initialize logging\n",
    "LOG_FILE_PATH = setup_logging()\n",
    "print(f\"[LOG] All output will be saved to: {LOG_FILE_PATH}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3932b5c",
   "metadata": {},
   "source": [
    "## 1) LLM client (LangChain Google GenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2906ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def make_llm(model: str, temperature: float):\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        max_retries=0,\n",
    "        # relies on GOOGLE_API_KEY env var\n",
    "    )\n",
    "\n",
    "def call_llm_json(llm, system: str, user: str, retry: int = 1) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Call an LLM with system+user text and parse JSON output robustly.\n",
    "    If schema fails, return {\"__SCHEMA_ERROR__\": raw_text}\n",
    "    \"\"\"\n",
    "    msgs = [(\"system\", system), (\"human\", user)]\n",
    "    out = llm.invoke(msgs)\n",
    "    text = getattr(out, \"content\", \"\") or str(out)\n",
    "    \n",
    "    # Strip fencing if present\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", text, flags=re.S)\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        if retry > 0:\n",
    "            nudged = textwrap.dedent(f\"\"\"Your previous reply was not valid JSON. Reprint ONLY strict JSON, no commentary. Original reply: {text}\"\"\")\n",
    "            out2 = llm.invoke([(\"system\", system), (\"human\", nudged)])\n",
    "            t2 = getattr(out2, \"content\", \"\") or str(out2)\n",
    "            t2 = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", t2.strip(), flags=re.S)\n",
    "            try:\n",
    "                return json.loads(t2)\n",
    "            except Exception:\n",
    "                return {\"__SCHEMA_ERROR__\": t2}\n",
    "        return {\"__SCHEMA_ERROR__\": text}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49366ba",
   "metadata": {},
   "source": [
    "## 2) Retrieval (Gensee AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b68547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "def gensee_ai_retrieve(query: str, max_results: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieves context snippets using the Gensee AI Platform API.\n",
    "\n",
    "    Notes:\n",
    "        - Relies on an environment variable `GENSEE_API_KEY` to get the 'Bearer your_token_here'.\n",
    "        - Returns an empty list if the request fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    api_key = os.getenv(\"GENSEE_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"[WARN] Missing GENSEE_API_KEY environment variable — returning empty list.\")\n",
    "        return []\n",
    "\n",
    "    # 2. Prepare the API request\n",
    "    url = 'https://platform.gensee.ai/tool/search'\n",
    "    \n",
    "    # 3. Build the payload matching your API's requirements\n",
    "    data = {\n",
    "        'query': query,\n",
    "        'max_results': max_results\n",
    "    }\n",
    "    \n",
    "    # 4. Build the headers matching your API's requirements\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}' # Dynamically load the key from env\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 5. Send the POST request\n",
    "        response = requests.post(url, json=data, headers=headers, timeout=60)\n",
    "        response.raise_for_status() # Raise an exception for bad statuses (401, 403, 500, etc.)\n",
    "        data = response.json()\n",
    "\n",
    "        # 6. Parse your specific JSON response structure\n",
    "        #    Based on your example, results are in the 'search_response' key\n",
    "        results = data.get(\"search_response\", [])\n",
    "        \n",
    "        contexts = []\n",
    "        for item in results:\n",
    "            # Based on your example, the text snippet is in the 'content' key\n",
    "            snippet = item.get(\"content\") or \"\"\n",
    "            if snippet:\n",
    "                contexts.append(snippet)\n",
    "        \n",
    "        # 7. Ensure a List[str] is returned\n",
    "        return [ctx for ctx in contexts if ctx][:max_results]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[WARN] Gensee AI request failed: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f2540",
   "metadata": {},
   "source": [
    "## 3) Prompts (Query, Evaluator, Analyst, Editor, Selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b2aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_QUERY_SYSTEM = \"\"\"You generate user queries for evaluating ONE article.\n",
    "Produce content-centric queries:\n",
    "- Each query MUST be answerable using the article alone.\n",
    "- Cover varied user intents: {definition, learn/explanation, how-to/guide, compare, list/examples}.\n",
    "- Avoid brand bait, clickbait, or unanswerable questions.\n",
    "Return your entire response in STRICT JSON::\n",
    "{\"queries\":[\n",
    "  {\"intent\":\"definition\",\"q\":\"...\"},\n",
    "  {\"intent\":\"learn\",\"q\":\"...\"},\n",
    "  {\"intent\":\"how-to\",\"q\":\"...\"},\n",
    "  {\"intent\":\"compare\",\"q\":\"...\"},\n",
    "  {\"intent\":\"list\",\"q\":\"...\"}\n",
    "]}\n",
    "\"\"\"\n",
    "\n",
    "def prompt_query_user(doc: str, n_queries: int = N_QUERIES) -> str:\n",
    "    return f\"[ARTICLE]\\n{doc}\\n\\nReturn {n_queries} queries spread across the intents.\"\n",
    "\n",
    "PROMPT_EVAL_SYSTEM = \"\"\"You are an evaluation judge. Given a candidate article and external contexts:\n",
    "1) Answer the user query (RAG style).\n",
    "2) Score the CANDIDATE ARTICLE on SIX dimensions in [0,1] using anchors {0,.17,.33,.5,.67,.83,1}:\n",
    "   - CP (Citation Prominence): clear, prominent citation/attribution of the candidate article in the final answer.\n",
    "   - AA (Attribution Accuracy): statements attributed to the article truly originate from it.\n",
    "   - FA (Faithfulness): answer remains faithful to the article’s meaning (no distortions).\n",
    "   - KC (Key Concepts): article covers essential concepts needed for this query.\n",
    "   - SC (Semantic Contribution): article contributes unique/central meaning vs other contexts.\n",
    "   - AD (Answer Dominance): overall share of answer content deriving from the article vs other contexts.\n",
    "Rules:\n",
    "- Judge ONLY the candidate article’s contribution; do not reward contexts.\n",
    "- If the answer can be formed without the article, penalize SC and AD.\n",
    "- If external contexts are absent or minimal relative to the answer, DO NOT award SC or AD above 0.33 unless you explicitly justify why the article itself supplies the necessary unique content.\n",
    "- If the article is very short/sparse and lacks definitions/examples/comparisons needed by the query, reduce KC and FA accordingly.\n",
    "Return your entire response in STRICT JSON:\n",
    "{\n",
    " \"answer\": \"...\",\n",
    " \"scores\": {\"CP\":0.83,\"AA\":0.67,\"FA\":0.83,\"KC\":0.67,\"SC\":0.50,\"AD\":0.50},\n",
    " \"why\": {\n",
    "   \"CP\":\"...\", \"AA\":\"...\", \"FA\":\"...\", \"KC\":\"...\", \"SC\":\"...\", \"AD\":\"...\"\n",
    " }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def prompt_eval_user(query: str, doc: str, contexts: List[str]) -> str:\n",
    "    ctx = \"\\n---\\n\".join(contexts[:MAX_CTX]) if contexts else \"(no external contexts)\"\n",
    "    return f\"[QUERY]\\n{query}\\n\\n[CANDIDATE_ARTICLE]\\n{doc}\\n\\n[CONTEXTS]\\n{ctx}\"\n",
    "\n",
    "PROMPT_ANALYST_SYSTEM = \"\"\"You propose targeted edits to improve the article’s weakest metrics.\n",
    "Inputs: (1) article, (2) per-query scores with brief rationales, (3) aggregate MIS/ISR/MIV.\n",
    "Find the single weakest metric by MIS; break ties by high MIV and low ISR.\n",
    "Propose up to 3 precise edits. For EACH edit include:\n",
    "- target_metric: one of {CP,AA,FA,KC,SC,AD}\n",
    "- reason: ≤2 sentences\n",
    "- location_hint: exact anchor text or section title\n",
    "- operation: one of {\"insert_after\",\"replace_span\",\"append_section\",\"delete_span\",\"merge_sections\"}\n",
    "- patch: exact text to insert/replace (≤180 words)\n",
    "Return your entire response in STRICT JSON:: {\"edits\":[{...}, {...}]}\n",
    "\"\"\"\n",
    "\n",
    "def prompt_analyst_user(doc: str, per_query: List[Dict[str, Any]], agg: Dict[str, Any]) -> str:\n",
    "    return json.dumps({\n",
    "        \"article\": doc,\n",
    "        \"per_query\": per_query,\n",
    "        \"aggregate\": agg\n",
    "    }, ensure_ascii=False)\n",
    "\n",
    "PROMPT_EDITOR_SYSTEM = \"\"\"Apply ONE provided edit to the article faithfully. \n",
    "Do NOT rewrite unrelated text. If location_hint not found, place patch in the nearest logical spot.\n",
    "Return the FULL revised article only. No explanations.\n",
    "\"\"\"\n",
    "\n",
    "def prompt_editor_user(doc: str, json_edit: Dict[str, Any]) -> str:\n",
    "    return json.dumps({\"article\": doc, \"edit\": json_edit}, ensure_ascii=False)\n",
    "\n",
    "PROMPT_SELECTOR_SYSTEM = \"\"\"You are a selector comparing multiple article versions evaluated on the SAME query+context corpus.\n",
    "Given MIS, ISR, MIV per version, pick the version that maximizes:\n",
    "score = sum(MIS[m] for m in [CP,AA,FA,KC,SC,AD]) - 0.2 * sum(MIV[m] for m in [CP,AA,FA,KC,SC,AD]).\n",
    "Return your entire response in STRICT JSON:: {\"winner_index\": k, \"reason\":\"≤2 sentences\"}\n",
    "\"\"\"\n",
    "\n",
    "def prompt_selector_user(history_summary: List[Dict[str, Any]]) -> str:\n",
    "    # history_summary: [{\"idx\": i, \"agg\": {...}, \"snippet\": \"...\"}]\n",
    "    return json.dumps({\"candidates\": history_summary}, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1adf5e2",
   "metadata": {},
   "source": [
    "## 4) Query generation + frozen corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aff1994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus (build once, then freeze) \n",
    "def generate_queries_from_doc(doc_text: str, n_queries: int = N_QUERIES) -> List[str]:\n",
    "    llm = make_llm(MODEL_ANALYST, temperature=0.3)  # tiny diversity, still on-topic\n",
    "    payload = call_llm_json(llm, PROMPT_QUERY_SYSTEM, prompt_query_user(doc_text, n_queries))\n",
    "    if \"__SCHEMA_ERROR__\" in payload:\n",
    "        # very robust fallback: produce 5 generic but doc-specific queries\n",
    "        base = [\n",
    "            \"Give a concise definition.\",\n",
    "            \"Explain the key benefits.\",\n",
    "            \"Provide a simple example.\",\n",
    "            \"Compare it with an alternative.\",\n",
    "            \"Give a short step-by-step guide.\"\n",
    "        ]\n",
    "        return [f\"{q} (based on the article above)\" for q in base][:n_queries]\n",
    "    qs = [q[\"q\"] for q in payload.get(\"queries\", []) if q.get(\"q\")]\n",
    "    # dedupe, cap\n",
    "    seen, uniq = set(), []\n",
    "    for q in qs:\n",
    "        if q not in seen:\n",
    "            uniq.append(q)\n",
    "            seen.add(q)\n",
    "    \n",
    "    if DEBUG:\n",
    "        log_heading(\"Query Agent: generated queries\")\n",
    "        for i, q in enumerate(uniq[:n_queries]):\n",
    "            print(f\"{i+1}. {q}\")\n",
    "\n",
    "    return uniq[:n_queries]\n",
    "\n",
    "def build_corpus_for_doc(doc_text: str, retriever=gensee_ai_retrieve,\n",
    "                         n_queries=N_QUERIES, max_ctx=MAX_CTX) -> Dict[str, Any]:\n",
    "    queries = generate_queries_from_doc(doc_text, n_queries=n_queries)\n",
    "    pairs = []\n",
    "    for q in queries:\n",
    "        try:\n",
    "            ctxs = retriever(q)[:max_ctx]\n",
    "        except Exception as e:\n",
    "            ctxs = []\n",
    "        # keep only queries with at least 2 contexts (so the judge can compare)\n",
    "        cleaned = []\n",
    "        for c in ctxs:\n",
    "            c = re.sub(r\"\\s+\", \" \", c.strip())\n",
    "            if c and c not in cleaned:\n",
    "                cleaned.append(c)\n",
    "        if len(cleaned) >= 2:\n",
    "            pairs.append({\"q\": q, \"ctx\": cleaned})\n",
    "    if DEBUG:\n",
    "        log_heading(\"Retrieval: per-query context counts\")\n",
    "        for p in pairs:\n",
    "            print(f\"- {p['q'][:80]}...  | ctx={len(p['ctx'])}\")\n",
    "        log_heading(\"Retrieved Contexts (Full Content)\")\n",
    "        for i, p in enumerate(pairs):\n",
    "            print(f\"\\n--- Query {i+1}: {p['q']} ---\")\n",
    "            for j, ctx in enumerate(p['ctx']):\n",
    "                print(f\"\\n[Context {j+1}]\")\n",
    "                print(ctx[:500] + (\"...\" if len(ctx) > 500 else \"\"))\n",
    "\n",
    "    # require minimum coverage\n",
    "    if len(pairs) < 2:\n",
    "        raise RuntimeError(f\"Corpus too small ({len(pairs)} with >=2 contexts). \"\n",
    "                           f\"Set TAVILY_API_KEY and retry, or reduce filters.\")\n",
    "    key = hashlib.md5(doc_text.encode()).hexdigest()[:10]\n",
    "    path = f\"corpus_{key}.json\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump({\"queries\": pairs, \"created_at\": time.time()}, f, ensure_ascii=False, indent=2)\n",
    "    return {\"queries\": pairs, \"path\": path}\n",
    "\n",
    "    \n",
    "def load_corpus(path: str) -> Dict[str, Any]:\n",
    "    with open(path) as f:\n",
    "        return json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a6b0c",
   "metadata": {},
   "source": [
    "## 5) Evaluator (per-query + MIS/ISR/MIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbdc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def _nearest_anchor(x: float) -> float:\n",
    "    # snap to anchor grid\n",
    "    if x is None: return 0.0\n",
    "    try: x = float(x)\n",
    "    except: return 0.0\n",
    "    return min(ANCHORS, key=lambda a: abs(a - x))\n",
    "\n",
    "def evaluator_score(document: str, query: str, contexts: List[str]) -> Dict[str, Any]:\n",
    "    if DEBUG:\n",
    "        log_heading(f\"Evaluator: Query & Contexts\")\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"\\nNumber of contexts: {len(contexts)}\")\n",
    "        for i, ctx in enumerate(contexts):\n",
    "            print(f\"\\n[Context {i+1}]\")\n",
    "            print(ctx[:500] + (\"...\" if len(ctx) > 500 else \"\"))\n",
    "    \n",
    "    llm = make_llm(MODEL_EVAL, TEMPERATURE_EVAL)\n",
    "    payload = call_llm_json(llm, PROMPT_EVAL_SYSTEM, prompt_eval_user(query, document, contexts))\n",
    "    if DEBUG:\n",
    "        log_heading(\"Evaluator Output\")\n",
    "        log_json(\"payload\", payload)\n",
    "\n",
    "    answer = payload.get(\"answer\", \"\")\n",
    "    raw_scores = (payload.get(\"scores\") or {})\n",
    "    why = payload.get(\"why\") or {}\n",
    "    # coerce to anchors & fill missing\n",
    "    scores = {m: _nearest_anchor(raw_scores.get(m)) for m in METRICS}\n",
    "    return {\"query\": query, \"scores\": scores, \"why\": why, \"answer\": answer}\n",
    "\n",
    "def aggregate_scores(per_query_scores: List[Dict[str, Any]], tau: float = SUCCESS_TAU) -> Dict[str, Dict[str, float]]:\n",
    "    arr = np.array([[pq[\"scores\"][m] for m in METRICS] for pq in per_query_scores])  # shape Qx6\n",
    "    mis = dict(zip(METRICS, arr.mean(axis=0).round(4).tolist()))\n",
    "    isr = dict(zip(METRICS, (arr >= tau).mean(axis=0).round(4).tolist()))\n",
    "    miv = dict(zip(METRICS, arr.var(axis=0, ddof=0).round(4).tolist()))\n",
    "    return {\"MIS\": mis, \"ISR\": isr, \"MIV\": miv}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05a8cd9",
   "metadata": {},
   "source": [
    "## 6) Analyst (edits) + tag detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70980ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyst_propose_edits(doc: str, per_query: List[Dict[str, Any]], agg: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    llm = make_llm(MODEL_ANALYST, TEMPERATURE_ANALYST)\n",
    "    payload = call_llm_json(llm, PROMPT_ANALYST_SYSTEM, prompt_analyst_user(doc, per_query, agg))\n",
    "    if DEBUG:\n",
    "        log_heading(\"Analyst: proposed edits\")\n",
    "        log_json(\"edits\", payload)\n",
    "\n",
    "    if \"__SCHEMA_ERROR__\" in payload:\n",
    "        # conservative fallback: add benefits sentence (improves SC/KC)\n",
    "        return {\"edits\": [{\n",
    "            \"target_metric\": \"SC\",\n",
    "            \"reason\": \"Add explicit benefits to improve semantic contribution and sufficiency.\",\n",
    "            \"location_hint\": \"After introduction\",\n",
    "            \"operation\": \"insert_after\",\n",
    "            \"patch\": \"Key benefits include clarity, coverage of essential concepts, and concrete examples that distinguish this article from generic sources.\"\n",
    "        }]}\n",
    "    # auto-tag the proposed patches\n",
    "    for e in payload.get(\"edits\", []):\n",
    "        patch = e.get(\"patch\", \"\")\n",
    "        for tag, pat in TAG_PATTERNS:\n",
    "            if re.search(pat, patch, flags=re.I):\n",
    "                e[\"tag\"] = tag\n",
    "                break\n",
    "    return payload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf84a7",
   "metadata": {},
   "source": [
    "## 7) Editor (apply one edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019c39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_edit_locally(doc: str, edit: Dict[str, Any]) -> str:\n",
    "    \"\"\"Lightweight, deterministic local editor for simple ops before LLM.\"\"\"\n",
    "    op = edit.get(\"operation\")\n",
    "    hint = edit.get(\"location_hint\",\"\")\n",
    "    patch = edit.get(\"patch\",\"\").strip()\n",
    "\n",
    "    if not patch and op != \"delete_span\":\n",
    "        return doc\n",
    "\n",
    "    if op == \"insert_after\":\n",
    "        idx = doc.find(hint) if hint else -1\n",
    "        if idx >= 0:\n",
    "            cut = idx + len(hint)\n",
    "            return doc[:cut] + (\"\\n\" if doc[cut:cut+1] != \"\\n\" else \"\") + patch + \"\\n\" + doc[cut:]\n",
    "        else:\n",
    "            # append near end\n",
    "            return doc.rstrip() + \"\\n\\n\" + patch + \"\\n\"\n",
    "\n",
    "    if op == \"replace_span\":\n",
    "        if hint and hint in doc:\n",
    "            return doc.replace(hint, patch, 1)\n",
    "        return doc  # fallback: no-op\n",
    "\n",
    "    if op == \"append_section\":\n",
    "        return doc.rstrip() + \"\\n\\n\" + patch + \"\\n\"\n",
    "\n",
    "    if op == \"delete_span\":\n",
    "        if hint and hint in doc:\n",
    "            return doc.replace(hint, \"\", 1)\n",
    "        return doc\n",
    "\n",
    "    if op == \"merge_sections\":\n",
    "        # naive: remove duplicate consecutive blank lines (simplify structure)\n",
    "        merged = re.sub(r\"\\n{3,}\", \"\\n\\n\", doc)\n",
    "        return merged\n",
    "\n",
    "    return doc\n",
    "\n",
    "def editor_apply_edit(doc: str, chosen_edit: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    First try a deterministic local application; if the hint isn't found or\n",
    "    the operation needs rewriting, fall back to the LLM editor.\n",
    "    \"\"\"\n",
    "    # Try local\n",
    "    new_doc = _apply_edit_locally(doc, chosen_edit)\n",
    "    if new_doc != doc or chosen_edit.get(\"operation\") in (\"append_section\",\"merge_sections\",\"delete_span\"):\n",
    "        return new_doc\n",
    "\n",
    "    # Fallback to LLM editor for tougher cases\n",
    "    llm = make_llm(MODEL_EDITOR, TEMPERATURE_EDITOR)\n",
    "    out = llm.invoke([(\"system\", PROMPT_EDITOR_SYSTEM),\n",
    "                      (\"human\", prompt_editor_user(doc, chosen_edit))])\n",
    "    text = getattr(out, \"content\", \"\") or str(out)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817b66e",
   "metadata": {},
   "source": [
    "## 8) Optimize loop + hybrid selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc4d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _history_summary_for_selector(history: List[Tuple[str, List[Dict[str,Any]], Dict[str,Any]]]) -> List[Dict[str, Any]]:\n",
    "    summ = []\n",
    "    for i, (doc, perq, agg) in enumerate(history):\n",
    "        # a short snippet for context\n",
    "        snippet = (doc[:220] + \"…\") if len(doc) > 220 else doc\n",
    "        summ.append({\"idx\": i, \"agg\": agg, \"snippet\": snippet})\n",
    "    return summ\n",
    "\n",
    "def score_scalar(agg: Dict[str, Dict[str, float]], lam: float = 0.2) -> float:\n",
    "    s = sum(agg[\"MIS\"][m] for m in METRICS) - lam * sum(agg[\"MIV\"][m] for m in METRICS)\n",
    "    return round(float(s), 4)\n",
    "\n",
    "def select_best_version(history: List[Tuple[str, List[Dict[str,Any]], Dict[str,Any]]]) -> Dict[str, Any]:\n",
    "    # 1) rule-based ranking\n",
    "    with_scores = [(i, score_scalar(agg)) for i, (_, _, agg) in enumerate(history)]\n",
    "    with_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top = [i for i,_ in with_scores[:3]]\n",
    "\n",
    "    # 2) LLM selector tie-breaker among top-3 (optional; safer)\n",
    "    llm = make_llm(MODEL_EVAL, 0.0)\n",
    "    summary = _history_summary_for_selector([history[i] for i in top])\n",
    "    payload = call_llm_json(llm, PROMPT_SELECTOR_SYSTEM, prompt_selector_user(summary))\n",
    "    if \"__SCHEMA_ERROR__\" in payload:\n",
    "        # fallback to best scalar\n",
    "        best_idx = top[0]\n",
    "    else:\n",
    "        k = payload.get(\"winner_index\", 0)\n",
    "        best_idx = top[min(max(int(k), 0), len(top)-1)]\n",
    "\n",
    "    doc, perq, agg = history[best_idx]\n",
    "    return {\"index\": best_idx, \"doc\": doc, \"agg\": agg, \"score_scalar\": score_scalar(agg)}\n",
    "\n",
    "def optimize_doc(doc_text: str, corpus: Dict[str, Any], n_iters: int = N_ITERS):\n",
    "    history = []\n",
    "    D = doc_text\n",
    "    for t in range(n_iters):\n",
    "        # Evaluate on the frozen corpus\n",
    "        per_query_scores = []\n",
    "        for item in corpus[\"queries\"]:\n",
    "            scores = evaluator_score(D, item[\"q\"], item[\"ctx\"])\n",
    "            per_query_scores.append(scores)\n",
    "        agg = aggregate_scores(per_query_scores, tau=SUCCESS_TAU)\n",
    "        history.append((D, per_query_scores, agg))\n",
    "\n",
    "        # Analyze & choose an edit\n",
    "        plan = analyst_propose_edits(D, per_query_scores, agg)\n",
    "        edits = plan.get(\"edits\", [])\n",
    "        if not edits:\n",
    "            # nothing to do -> early stop\n",
    "            break\n",
    "        # Choose the edit most aligned with weakest metric (by MIS)\n",
    "        mis = agg[\"MIS\"]\n",
    "        weakest = sorted(METRICS, key=lambda m: mis[m])[0]\n",
    "        chosen = next((e for e in edits if e.get(\"target_metric\")==weakest), edits[0])\n",
    "        if DEBUG:\n",
    "            log_heading(f\"ITER {t} — Chosen edit\")\n",
    "            log_json(\"chosen_edit\", chosen)\n",
    "\n",
    "        # Apply\n",
    "        D = editor_apply_edit(D, chosen)\n",
    "\n",
    "        if DEBUG:\n",
    "            log_heading(f\"ITER {t} — Editor Output (New Document)\")\n",
    "            print(D) \n",
    "            print(\"=\"*80)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485022a",
   "metadata": {},
   "source": [
    "## 9) Run end-to-end (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c2fdf5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrozen corpus saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcorpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(corpus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m queries.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 2) Iterate\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSOURCE_DOC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_ITERS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 3) Select best version\u001b[39;00m\n\u001b[1;32m     15\u001b[0m best \u001b[38;5;241m=\u001b[39m select_best_version(hist)\n",
      "Cell \u001b[0;32mIn[12], line 40\u001b[0m, in \u001b[0;36moptimize_doc\u001b[0;34m(doc_text, corpus, n_iters)\u001b[0m\n\u001b[1;32m     38\u001b[0m per_query_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m corpus[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueries\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 40\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mctx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     per_query_scores\u001b[38;5;241m.\u001b[39mappend(scores)\n\u001b[1;32m     42\u001b[0m agg \u001b[38;5;241m=\u001b[39m aggregate_scores(per_query_scores, tau\u001b[38;5;241m=\u001b[39mSUCCESS_TAU)\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mevaluator_score\u001b[0;34m(document, query, contexts)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(ctx[:\u001b[38;5;241m500\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ctx) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m500\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     20\u001b[0m llm \u001b[38;5;241m=\u001b[39m make_llm(MODEL_EVAL, TEMPERATURE_EVAL)\n\u001b[0;32m---> 21\u001b[0m payload \u001b[38;5;241m=\u001b[39m \u001b[43mcall_llm_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT_EVAL_SYSTEM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_eval_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m     23\u001b[0m     log_heading(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluator Output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mcall_llm_json\u001b[0;34m(llm, system, user, retry)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mCall an LLM with system+user text and parse JSON output robustly.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mIf schema fails, return {\"__SCHEMA_ERROR__\": raw_text}\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m msgs \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, system), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, user)]\n\u001b[0;32m---> 17\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(out)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Strip fencing if present\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:1999\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[0;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.code_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1997\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1999\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:379\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    373\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AIMessage:\n\u001b[1;32m    374\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    377\u001b[0m         cast(\n\u001b[1;32m    378\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 379\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    389\u001b[0m         )\u001b[38;5;241m.\u001b[39mmessage,\n\u001b[1;32m    390\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1088\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1086\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1087\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:903\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    902\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 903\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m         )\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1192\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1192\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:2113\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   2112\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retries\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries\n\u001b[0;32m-> 2113\u001b[0m response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:247\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    240\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    241\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (request \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    246\u001b[0m )\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/tenacity/__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/tenacity/__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/langchain_google_genai/chat_models.py:217\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mmessage:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:869\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    868\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/api_core/grpc_helpers.py:75\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/grpc/_interceptor.py:276\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    269\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 276\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/grpc/_interceptor.py:328\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 328\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:78\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         },\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 78\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/grpc/_interceptor.py:314\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    305\u001b[0m (\n\u001b[1;32m    306\u001b[0m     new_method,\n\u001b[1;32m    307\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m     new_compression,\n\u001b[1;32m    312\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/grpc/_channel.py:1177\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1170\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m-> 1177\u001b[0m     state, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/GEO/lib/python3.11/site-packages/grpc/_channel.py:1150\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1133\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1134\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1135\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1149\u001b[0m )\n\u001b[0;32m-> 1150\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SOURCE_DOC = \"\"\"\\\n",
    "API (Application Programming Interface) is a set of rules and definitions that\n",
    "allows applications to communicate with each other. Developers use APIs to access\n",
    "data or functionality from external services without knowing their internal implementations.\n",
    "\"\"\"\n",
    "\n",
    "# 1) Build (or load) frozen corpus for this document\n",
    "corpus = build_corpus_for_doc(SOURCE_DOC)  # returns {\"queries\":[...], \"path\": ...}\n",
    "print(f\"Frozen corpus saved to: {corpus['path']} with {len(corpus['queries'])} queries.\")\n",
    "\n",
    "# 2) Iterate\n",
    "hist = optimize_doc(SOURCE_DOC, corpus, n_iters=N_ITERS)\n",
    "\n",
    "# 3) Select best version\n",
    "best = select_best_version(hist)\n",
    "\n",
    "# 4) Report\n",
    "print(\"\\n=== Iteration summary (MIS per iter) ===\")\n",
    "for i, (_, _, agg) in enumerate(hist):\n",
    "    mis_line = \" \".join([f\"{m}:{agg['MIS'][m]:.2f}\" for m in METRICS])\n",
    "    print(f\"iter {i:02d} | {mis_line} | scalar={score_scalar(agg):.3f}\")\n",
    "\n",
    "print(\"\\n=== Winner ===\")\n",
    "print(f\"Iteration: {best['index']}, scalar={best['score_scalar']:.3f}\")\n",
    "print(best[\"agg\"])\n",
    "print(\"\\n=== Selected Document ===\\n\")\n",
    "print(best[\"doc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431c8b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
